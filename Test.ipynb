{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.loading_utils import load_model, get_device\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from utils.event_readers import FixedSizeEventReader, FixedDurationEventReader\n",
    "from utils.inference_utils import events_to_voxel_grid, events_to_voxel_grid_pytorch\n",
    "from utils.timers import Timer\n",
    "import time \n",
    "from image_reconstructor import ImageReconstructor\n",
    "from options.inference_options import set_inference_options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -c PATH_TO_MODEL -i INPUT_FILE\n",
      "ipykernel_launcher.py: error: the following arguments are required: -c/--path_to_model, -i/--input_file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "        description='Evaluating a trained network')\n",
    "parser.add_argument('-c', '--path_to_model', required=True, type=str,\n",
    "                    help='path to model weights')\n",
    "parser.add_argument('-i', '--input_file', required=True, type=str)\n",
    "# parser.add_argument('--fixed_duration', dest='fixed_duration', action='store_true')\n",
    "# parser.set_defaults(fixed_duration=False)\n",
    "# parser.add_argument('-N', '--window_size', default=None, type=int,\n",
    "#                     help=\"Size of each event window, in number of events. Ignored if --fixed_duration=True\")\n",
    "# parser.add_argument('-T', '--window_duration', default=33.33, type=float,\n",
    "#                     help=\"Duration of each event window, in milliseconds. Ignored if --fixed_duration=False\")\n",
    "# parser.add_argument('--num_events_per_pixel', default=0.35, type=float,\n",
    "#                     help='in case N (window size) is not specified, it will be \\\n",
    "#                             automatically computed as N = width * height * num_events_per_pixel')\n",
    "# parser.add_argument('--skipevents', default=0, type=int)\n",
    "# parser.add_argument('--suboffset', default=0, type=int)\n",
    "# parser.add_argument('--compute_voxel_grid_on_cpu', dest='compute_voxel_grid_on_cpu', action='store_true')\n",
    "# parser.set_defaults(compute_voxel_grid_on_cpu=False)\n",
    "\n",
    "# set_inference_options(parser)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"pretrained/E2VID_lightweight.pth.tar\"\n",
    "input_file = \"data/dynamic_6dof.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x7f85c11324c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(input_file, delim_whitespace=True, header=None,\n",
    "                                    names=['t', 'x', 'y', 'pol'],\n",
    "                                    dtype={'t': np.float64, 'x': np.int16, 'y': np.int16, 'pol': np.int16},\n",
    "                                    engine='c',\n",
    "                                    skiprows= 1, chunksize=10000, nrows=None, memory_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_csv(input_file, delim_whitespace=True, header=None,\n",
    "                                    names=['t', 'x', 'y', 'pol'],\n",
    "                                    nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t    x     y  pol\n",
      "0  2.400000e+02  180   NaN  NaN\n",
      "1  1.473348e+09   80  22.0  0.0\n"
     ]
    }
   ],
   "source": [
    "print(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor size: 240 x 180\n"
     ]
    }
   ],
   "source": [
    "# Read sensor size from the first first line of the event file\n",
    "path_to_events = input_file\n",
    "\n",
    "header = pd.read_csv(path_to_events, delim_whitespace=True, header=None, names=['width', 'height'],\n",
    "                        dtype={'width': int, 'height': int},\n",
    "                        nrows=1)\n",
    "    \n",
    "width, height = header.values[0]\n",
    "print('Sensor size: {} x {}'.format(width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240, 180])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pretrained/E2VID_lightweight.pth.tar...\n",
      "Using TransposedConvLayer (fast, with checkerboard artefacts)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = load_model(path_to_model, device)\n",
    "model = model.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E2VIDRecurrent(\n",
       "  (unetrecurrent): UNetRecurrent(\n",
       "    (head): ConvLayer(\n",
       "      (conv2d): Conv2d(5, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (encoders): ModuleList(\n",
       "      (0): RecurrentConvLayer(\n",
       "        (conv): ConvLayer(\n",
       "          (conv2d): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "          (norm_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (recurrent_block): ConvLSTM(\n",
       "          (Gates): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): RecurrentConvLayer(\n",
       "        (conv): ConvLayer(\n",
       "          (conv2d): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "          (norm_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (recurrent_block): ConvLSTM(\n",
       "          (Gates): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): RecurrentConvLayer(\n",
       "        (conv): ConvLayer(\n",
       "          (conv2d): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "          (norm_layer): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (recurrent_block): ConvLSTM(\n",
       "          (Gates): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (decoders): ModuleList(\n",
       "      (0): TransposedConvLayer(\n",
       "        (transposed_conv2d): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (norm_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): TransposedConvLayer(\n",
       "        (transposed_conv2d): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (norm_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): TransposedConvLayer(\n",
       "        (transposed_conv2d): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (norm_layer): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (pred): ConvLayer(\n",
       "      (conv2d): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (norm_layer): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(3) tensor(0.7000) tensor(0.3000) tensor(0.7000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ts = 3.7\n",
    "pols = +1\n",
    "ts = torch.tensor(ts)\n",
    "pols = torch.tensor(pols)\n",
    "\n",
    "tis = torch.floor(ts)  #向下取整\n",
    "tis_long = tis.long()  #转为Int64\n",
    "dts = ts - tis         #找到小数\n",
    "vals_left = pols * (1.0 - dts.float())\n",
    "vals_right = pols * dts.float()\n",
    "\n",
    "print(tis,\n",
    "tis_long,\n",
    "dts,\n",
    "vals_left,\n",
    "vals_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "valid_indices = tis < 5\n",
    "print(valid_indices,valid_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_indices &= tis >= 100\n",
    "valid_indices\n",
    "a=True\n",
    "b=True\n",
    "a &= b\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7254, 0.1629, 0.4855, 0.7100],\n",
      "        [0.5247, 0.0156, 0.5747, 0.6553]])\n",
      "tensor([[0.7254],\n",
      "        [0.5247]])\n",
      "tensor([[0.1629, 0.4855, 0.7100],\n",
      "        [0.0156, 0.5747, 0.6553]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.rand(2,4)\n",
    "print(a)\n",
    "print(a[:,:1])\n",
    "print(a[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.randn(4,1) #随机生成一个shape（3，4）的tensort\n",
    "b=torch.randn(4,3) #随机生成一个shape（2，4）的tensor\n",
    "\n",
    "c = torch.cat([a,b],dim=1) \n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand(10, requires_grad=True).cuda()\n",
    "b = a+1\n",
    "\n",
    "b.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minghong@corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/build/aten/src/ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minghong@corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/build/aten/src/ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a1 = torch.rand([4, 4], requires_grad=True).squeeze(0)\n",
    "b1 = a1**2\n",
    "b1.sum().backward()\n",
    "print(a1.grad)\n",
    "print(b1.grad)\n",
    "a2 = torch.rand([1, 4, 4], requires_grad=True).unsqueeze(0)\n",
    "b2 = a2**2\n",
    "b2.sum().backward()\n",
    "print(a2.grad)\n",
    "print(b2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "True\n",
      "tensor([[[0.6153, 1.5961, 0.4122, 0.5027],\n",
      "         [1.8332, 1.1463, 1.7687, 0.2403],\n",
      "         [0.2135, 1.7001, 0.5735, 1.6498],\n",
      "         [0.1901, 1.9154, 1.5768, 0.9390]]])\n",
      "torch.Size([1, 4, 4])\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a1 = torch.rand([4, 4], requires_grad=True)\n",
    "\n",
    "c1 = a1 * 2 \n",
    "b1 = c1.squeeze(0)**2\n",
    "a1.retain_grad()\n",
    "b1.sum().backward()\n",
    "print(a1.is_leaf)\n",
    "print(a1.grad.shape)\n",
    "print(a1.shape)\n",
    "a2 = torch.rand([1, 4, 4], requires_grad=True)\n",
    "b2 = a2.unsqueeze(0)**2\n",
    "b2.sum().backward()\n",
    "print(a2.is_leaf)\n",
    "print(a2.grad)\n",
    "print(a2.grad.shape)\n",
    "print(a2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[1.3048, 0.3445, 2.9272, 3.9529],\n",
      "        [1.7340, 3.0695, 3.4180, 1.3781],\n",
      "        [3.8073, 1.4407, 1.6093, 1.3925],\n",
      "        [0.2178, 3.6619, 0.6721, 2.2217]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a1 = torch.rand([4, 4], requires_grad=True)\n",
    "\n",
    "a1 = a1 * 2 \n",
    "b1 = a1.squeeze(0)**2\n",
    "a1.retain_grad()\n",
    "b1.sum().backward()\n",
    "print(a1.is_leaf)\n",
    "print(a1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  True   tensor([2., 2.])\n",
      "b:  True   tensor([2., 2.])\n",
      "c:  False   None\n",
      "d:  True   tensor([10.])\n",
      "e:  False   None\n",
      "o:  False   None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minghong@corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/build/aten/src/ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor([1,2]).requires_grad_() \n",
    "b = torch.Tensor([3,4]).requires_grad_() \n",
    "d = torch.Tensor([2]).requires_grad_() \n",
    "c = a + b \n",
    "e = c * d \n",
    "o = e.sum()     \n",
    " \n",
    "o.backward()\n",
    "print('a: ',a.is_leaf,' ',a.grad)\n",
    "print('b: ',b.is_leaf,' ',b.grad)\n",
    "print('c: ',c.is_leaf,' ',c.grad)\n",
    "print('d: ',d.is_leaf,' ',d.grad)\n",
    "print('e: ',e.is_leaf,' ',e.grad)\n",
    "print('o: ',o.is_leaf,' ',o.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/minghong@corp.sse.tongji.edu.cn/rpg_e2vid/Test.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707530354e6f74496e5363686f6f6c227d/home/minghong%40corp.sse.tongji.edu.cn/rpg_e2vid/Test.ipynb#ch0000024vscode-remote?line=5'>6</a>\u001b[0m e \u001b[39m=\u001b[39m c \u001b[39m*\u001b[39m d \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707530354e6f74496e5363686f6f6c227d/home/minghong%40corp.sse.tongji.edu.cn/rpg_e2vid/Test.ipynb#ch0000024vscode-remote?line=6'>7</a>\u001b[0m o \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39msum()     \n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707530354e6f74496e5363686f6f6c227d/home/minghong%40corp.sse.tongji.edu.cn/rpg_e2vid/Test.ipynb#ch0000024vscode-remote?line=8'>9</a>\u001b[0m o\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707530354e6f74496e5363686f6f6c227d/home/minghong%40corp.sse.tongji.edu.cn/rpg_e2vid/Test.ipynb#ch0000024vscode-remote?line=9'>10</a>\u001b[0m \u001b[39m# print('a: ',a.is_leaf,' ',a.grad)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707530354e6f74496e5363686f6f6c227d/home/minghong%40corp.sse.tongji.edu.cn/rpg_e2vid/Test.ipynb#ch0000024vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# print('b: ',b.is_leaf,' ',b.grad)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707530354e6f74496e5363686f6f6c227d/home/minghong%40corp.sse.tongji.edu.cn/rpg_e2vid/Test.ipynb#ch0000024vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mc: \u001b[39m\u001b[39m'\u001b[39m,c\u001b[39m.\u001b[39mis_leaf,\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m,c\u001b[39m.\u001b[39mgrad)\n",
      "File \u001b[0;32m~/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/minghong%40corp.sse.tongji.edu.cn/.conda/envs/E2VID/lib/python3.9/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor([1,2]).requires_grad_() \n",
    "b = torch.Tensor([3,4]).requires_grad_() \n",
    "d = torch.Tensor([2]).requires_grad_() \n",
    "c = a + b \n",
    "e = c * d \n",
    "o = e.sum()     \n",
    " \n",
    "o.backward()\n",
    "print('a: ',a.is_leaf,' ',a.grad)\n",
    "print('b: ',b.is_leaf,' ',b.grad)\n",
    "print('c: ',c.is_leaf,' ',c.grad)\n",
    "print('d: ',d.is_leaf,' ',d.grad)\n",
    "print('e: ',e.is_leaf,' ',e.grad)\n",
    "print('o: ',o.is_leaf,' ',o.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = [3,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor([1.233,2.232])\n",
    "print(a.dtype)\n",
    "a = a.long()\n",
    "print(a.dtype)\n",
    "print(a)\n",
    "b = torch.Tensor([1473347517.019522666931])\n",
    "b = b* (10**10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ec60040f1744a8a87706cb6216d26e22b09d753b89ccd492ee81b56191c2789"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('E2VID': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
