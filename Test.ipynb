{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.loading_utils import load_model, get_device\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from utils.event_readers import FixedSizeEventReader, FixedDurationEventReader\n",
    "from utils.inference_utils import events_to_voxel_grid, events_to_voxel_grid_pytorch\n",
    "from utils.timers import Timer\n",
    "import time \n",
    "from image_reconstructor import ImageReconstructor\n",
    "from options.inference_options import set_inference_options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -c PATH_TO_MODEL -i INPUT_FILE\n",
      "ipykernel_launcher.py: error: the following arguments are required: -c/--path_to_model, -i/--input_file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "        description='Evaluating a trained network')\n",
    "parser.add_argument('-c', '--path_to_model', required=True, type=str,\n",
    "                    help='path to model weights')\n",
    "parser.add_argument('-i', '--input_file', required=True, type=str)\n",
    "# parser.add_argument('--fixed_duration', dest='fixed_duration', action='store_true')\n",
    "# parser.set_defaults(fixed_duration=False)\n",
    "# parser.add_argument('-N', '--window_size', default=None, type=int,\n",
    "#                     help=\"Size of each event window, in number of events. Ignored if --fixed_duration=True\")\n",
    "# parser.add_argument('-T', '--window_duration', default=33.33, type=float,\n",
    "#                     help=\"Duration of each event window, in milliseconds. Ignored if --fixed_duration=False\")\n",
    "# parser.add_argument('--num_events_per_pixel', default=0.35, type=float,\n",
    "#                     help='in case N (window size) is not specified, it will be \\\n",
    "#                             automatically computed as N = width * height * num_events_per_pixel')\n",
    "# parser.add_argument('--skipevents', default=0, type=int)\n",
    "# parser.add_argument('--suboffset', default=0, type=int)\n",
    "# parser.add_argument('--compute_voxel_grid_on_cpu', dest='compute_voxel_grid_on_cpu', action='store_true')\n",
    "# parser.set_defaults(compute_voxel_grid_on_cpu=False)\n",
    "\n",
    "# set_inference_options(parser)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"pretrained/E2VID_lightweight.pth.tar\"\n",
    "input_file = \"data/dynamic_6dof.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x7f85c11324c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(input_file, delim_whitespace=True, header=None,\n",
    "                                    names=['t', 'x', 'y', 'pol'],\n",
    "                                    dtype={'t': np.float64, 'x': np.int16, 'y': np.int16, 'pol': np.int16},\n",
    "                                    engine='c',\n",
    "                                    skiprows= 1, chunksize=10000, nrows=None, memory_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_csv(input_file, delim_whitespace=True, header=None,\n",
    "                                    names=['t', 'x', 'y', 'pol'],\n",
    "                                    nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t    x     y  pol\n",
      "0  2.400000e+02  180   NaN  NaN\n",
      "1  1.473348e+09   80  22.0  0.0\n"
     ]
    }
   ],
   "source": [
    "print(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor size: 240 x 180\n"
     ]
    }
   ],
   "source": [
    "# Read sensor size from the first first line of the event file\n",
    "path_to_events = input_file\n",
    "\n",
    "header = pd.read_csv(path_to_events, delim_whitespace=True, header=None, names=['width', 'height'],\n",
    "                        dtype={'width': int, 'height': int},\n",
    "                        nrows=1)\n",
    "    \n",
    "width, height = header.values[0]\n",
    "print('Sensor size: {} x {}'.format(width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240, 180])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model pretrained/E2VID_lightweight.pth.tar...\n",
      "Using TransposedConvLayer (fast, with checkerboard artefacts)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = load_model(path_to_model, device)\n",
    "model = model.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E2VIDRecurrent(\n",
       "  (unetrecurrent): UNetRecurrent(\n",
       "    (head): ConvLayer(\n",
       "      (conv2d): Conv2d(5, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (encoders): ModuleList(\n",
       "      (0): RecurrentConvLayer(\n",
       "        (conv): ConvLayer(\n",
       "          (conv2d): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "          (norm_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (recurrent_block): ConvLSTM(\n",
       "          (Gates): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): RecurrentConvLayer(\n",
       "        (conv): ConvLayer(\n",
       "          (conv2d): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "          (norm_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (recurrent_block): ConvLSTM(\n",
       "          (Gates): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): RecurrentConvLayer(\n",
       "        (conv): ConvLayer(\n",
       "          (conv2d): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "          (norm_layer): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (recurrent_block): ConvLSTM(\n",
       "          (Gates): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (decoders): ModuleList(\n",
       "      (0): TransposedConvLayer(\n",
       "        (transposed_conv2d): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (norm_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): TransposedConvLayer(\n",
       "        (transposed_conv2d): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (norm_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): TransposedConvLayer(\n",
       "        (transposed_conv2d): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (norm_layer): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (pred): ConvLayer(\n",
       "      (conv2d): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (norm_layer): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(3) tensor(0.7000) tensor(0.3000) tensor(0.7000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ts = 3.7\n",
    "pols = +1\n",
    "ts = torch.tensor(ts)\n",
    "pols = torch.tensor(pols)\n",
    "\n",
    "tis = torch.floor(ts)  #向下取整\n",
    "tis_long = tis.long()  #转为Int64\n",
    "dts = ts - tis         #找到小数\n",
    "vals_left = pols * (1.0 - dts.float())\n",
    "vals_right = pols * dts.float()\n",
    "\n",
    "print(tis,\n",
    "tis_long,\n",
    "dts,\n",
    "vals_left,\n",
    "vals_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "valid_indices = tis < 5\n",
    "print(valid_indices,valid_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_indices &= tis >= 100\n",
    "valid_indices\n",
    "a=True\n",
    "b=True\n",
    "a &= b\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7254, 0.1629, 0.4855, 0.7100],\n",
      "        [0.5247, 0.0156, 0.5747, 0.6553]])\n",
      "tensor([[0.7254],\n",
      "        [0.5247]])\n",
      "tensor([[0.1629, 0.4855, 0.7100],\n",
      "        [0.0156, 0.5747, 0.6553]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.rand(2,4)\n",
    "print(a)\n",
    "print(a[:,:1])\n",
    "print(a[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.randn(4,1) #随机生成一个shape（3，4）的tensort\n",
    "b=torch.randn(4,3) #随机生成一个shape（2，4）的tensor\n",
    "\n",
    "c = torch.cat([a,b],dim=1) \n",
    "print(c.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ec60040f1744a8a87706cb6216d26e22b09d753b89ccd492ee81b56191c2789"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('E2VID': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
